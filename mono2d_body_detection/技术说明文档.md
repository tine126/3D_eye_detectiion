# mono2d_body_detection 技术说明文档

> 版本: 2.5.0 | 维护者: zhukao | 日期: 2026-01-27

---

## (A) 仓库地图与模块职责

### 目录树（≤3层）

```
mono2d_body_detection/
├── CMakeLists.txt                      # 构建配置
├── package.xml                         # ROS2包定义
├── README.md / README_cn.md            # 文档
├── LICENSE                             # Apache 2.0
├── config/                             # 配置与模型资源
│   ├── iou2_method_param.json          # MOT跟踪参数(IOU匹配)
│   ├── iou2_euclid_method_param.json   # MOT跟踪参数(欧氏距离匹配)
│   ├── person_body.jpg                 # 测试图片
│   ├── 960x544.nv12                    # 测试NV12图片
│   ├── x3/                             # RDK X3 模型
│   ├── x5/                             # RDK X5 模型
│   ├── Rdkultra/                       # RDK Ultra 模型
│   ├── s100/                           # RDK S100 模型 (yolo-pose)
│   └── s600/                           # RDK S600 模型 (yolo-pose)
├── include/
│   ├── mono2d_body_det_node.h          # 主节点头文件
│   └── post_process/
│       └── yolo_pose_parser.h          # YOLO-Pose后处理头文件
├── src/
│   ├── main.cpp                        # 程序入口
│   ├── mono2d_body_det_node.cpp        # 主节点实现
│   └── post_process/
│       └── yolo_pose_parser.cpp        # YOLO-Pose后处理实现
├── launch/
│   ├── mono2d_body_detection.launch.py              # 带相机启动
│   └── mono2d_body_detection_without_camera.launch.py # 无相机启动
└── imgs/                               # 文档图片
```

### 模块职责与边界

| 模块 | 职责 | 边界定位 |
|------|------|----------|
| **mono2d_body_det_node** | 核心检测节点，继承DnnNode，负责图像订阅、预处理、推理调度、后处理、结果发布 | `include/mono2d_body_det_node.h`, `src/mono2d_body_det_node.cpp` |
| **yolo_pose_parser** | YOLO-Pose模型专用后处理，解析bbox+关键点，执行NMS | `include/post_process/yolo_pose_parser.h`, `src/post_process/yolo_pose_parser.cpp` |
| **NodeOutputManage** | 输出排序管理器，解决异步推理输出乱序问题 | `include/mono2d_body_det_node.h:61-76` |
| **FasterRcnnOutput** | 推理输出数据结构，携带header、pyramid、时间戳 | `include/mono2d_body_det_node.h:78-86` |
| **config/** | 模型文件(.hbm)、MOT配置(.json)、测试资源 | 按平台分目录 |
| **launch/** | 启动配置，组合相机/编解码/检测/Web节点 | 支持MIPI/USB/本地回放 |

---

## (B) Package/Target 清单

### 包信息

- **包名**: `mono2d_body_detection`
- **版本**: 2.5.0
- **构建系统**: ament_cmake
- **C++标准**: C++14

### 编译目标

| Target | 类型 | 入口文件 | 说明 |
|--------|------|----------|------|
| `mono2d_body_detection_component` | 共享库 | `src/main.cpp`, `src/mono2d_body_det_node.cpp`, `src/post_process/yolo_pose_parser.cpp` | ROS2 Component库 |
| `mono2d_body_detection` | 可执行文件 | 由rclcpp_components自动生成 | 独立可执行节点 |

**定位**: `CMakeLists.txt:111-141`

### 依赖清单

| 依赖包 | 用途 |
|--------|------|
| `rclcpp` | ROS2核心 |
| `dnn_node` | BPU推理框架封装 |
| `cv_bridge` | OpenCV与ROS图像转换 |
| `sensor_msgs` | 标准图像消息 |
| `hbm_img_msgs` | 共享内存图像消息 |
| `ai_msgs` | AI感知结果消息 |
| `hobot_cv` | 地平线图像处理库 |
| `hobot_mot` | 多目标跟踪库(非X86平台) |
| `rclcpp_components` | 组件注册 |

**定位**: `package.xml:17-25`, `CMakeLists.txt:37-46`

### 编译选项（平台宏）

| 平台 | 宏定义 | PREFIX_PATH |
|------|--------|-------------|
| X3 | `BPU_LIBDNN` | x3 |
| X5 | `BPU_LIBDNN` | x5 |
| Rdkultra | `BPU_LIBDNN` | rdkultra |
| S100 | - | s100 |
| S600 | - | s600 |
| X86 | `PLATFORM_X86` | x3 |

**定位**: `CMakeLists.txt:57-91`

### 安装资源

| 资源 | 安装路径 |
|------|----------|
| 可执行文件 | `lib/mono2d_body_detection/` |
| 组件库 | `lib/` |
| 平台模型 | `lib/mono2d_body_detection/config/` |
| MOT配置 | `lib/mono2d_body_detection/config/` |
| 测试图片 | `lib/mono2d_body_detection/config/` |
| Launch文件 | `share/mono2d_body_detection/launch/` |

**定位**: `CMakeLists.txt:147-180`

---

## (C) ROS2 通信接口表

### Topics

| Topic名称 | 消息类型 | 方向 | 节点 | QoS | 频率 | frame_id/时间戳策略 |
|-----------|----------|------|------|-----|------|---------------------|
| `/hobot_mono2d_body_detection` | `ai_msgs/msg/PerceptionTargets` | 发布 | Mono2dBodyDetNode | 默认(depth=10) | 与输入同步 | 继承输入图像的header |
| `/hbmem_img` | `hbm_img_msgs/msg/HbmMsg1080P` | 订阅 | Mono2dBodyDetNode | SensorDataQoS | 相机帧率 | 使用`time_stamp`字段 |
| `/image_raw` | `sensor_msgs/msg/Image` | 订阅 | Mono2dBodyDetNode | 默认(depth=10) | 相机帧率 | 使用`header.stamp` |

**定位**:
- 发布: `mono2d_body_det_node.cpp:399-400`
- SharedMem订阅: `mono2d_body_det_node.cpp:433-439`
- ROS订阅: `mono2d_body_det_node.cpp:447-451`

### 订阅选择逻辑

```
is_shared_mem_sub_ == 1 → 订阅 /hbmem_img (SharedMem, 零拷贝)
is_shared_mem_sub_ == 0 → 订阅 /image_raw (标准ROS Image)
```

**定位**: `mono2d_body_det_node.cpp:413-452`

### 输出消息结构 (ai_msgs/msg/PerceptionTargets)

```yaml
header:                   # 继承输入图像时间戳
  stamp                   # 原始图像时间戳
  frame_id                # 原始图像frame_id
fps:                      # 输出帧率
perfs[]:                  # 性能统计数组
  - type: "{model_name}_preprocess"
  - type: "{model_name}_predict_infer"
  - type: "{model_name}_predict_parse"
  - type: "{model_name}_postprocess"
  - type: "{model_name}_pipeline"
targets[]:                # 检测目标数组
  - type: "person"
    track_id              # 跟踪ID (track_mode=1时有效)
    rois[]:               # 检测框
      - type: "body"/"head"/"face"/"hand"
        rect: {x_offset, y_offset, width, height}
    points[]:             # 关键点
      - type: "body_kps"
        point[]: {x, y}
        confidence[]
disappeared_targets[]:    # 消失目标(用于跟踪)
```

**定位**: `mono2d_body_det_node.cpp:546-763`

---

## (D) 调用链

### 完整调用链图

```
Launch文件
    │
    ▼
main.cpp:21-29
    │ rclcpp::init() → rclcpp::spin(Mono2dBodyDetNode)
    ▼
Mono2dBodyDetNode::Mono2dBodyDetNode() [构造函数]
    │ mono2d_body_det_node.cpp:296-458
    │
    ├─► declare/get_parameter()         # 参数声明与获取 :298-324
    ├─► DnnNode::Init()                 # 加载模型 :341
    ├─► GetModel()                      # 获取模型信息 :348-363
    ├─► 创建 parser_para_               # KPS解析参数 :371-396
    ├─► create_publisher()              # 创建AI消息发布者 :399-400
    ├─► GetModelInputSize()             # 获取模型输入尺寸 :402-411
    ├─► create_subscription()           # 创建图像订阅 :413-452
    │   ├─► SharedMemImgProcess (SharedMem模式)
    │   └─► RosImgProcess (ROS模式)
    └─► 初始化 hobot_mots_              # MOT跟踪器 :454-457
```

### 图像处理回调链

```
SharedMemImgProcess() / RosImgProcess()
    │ mono2d_body_det_node.cpp:839-963 / 966-1094
    │
    ├─► 抽帧检查 (image_gap_)           # :844-848 / 971-975
    ├─► 计算 width_scale_, height_scale_ # :858-859 / 987-988
    │
    ▼ [预处理]
    ├─► hobot_cv::hobotcv_resize()      # NV12 resize (如需) :893-894 / 1013-1014
    ├─► ImageProc::GetNV12PyramidFromNV12Img()  # 构建金字塔 :898-911 / 1018-1031
    │   或 ImageProc::GetNV12PyramidFromBGRImg() # BGR转NV12 :888-889
    │
    ▼ [推理]
    ├─► node_output_manage_ptr_->Feed() # 记录帧时间戳 :939-941 / 1065-1067
    └─► Predict()                       # :946 / 1077
            │
            ▼
        DnnNode::Run()                  # 调用BPU推理 :836
            │
            ▼ [异步回调]
        PostProcess()                   # :474-827
```

### 后处理调用链

```
PostProcess()
    │ mono2d_body_det_node.cpp:474-827
    │
    ├─► node_output_manage_ptr_->Feed() # 输出排序 :489
    │
    ▼ [解析]
    ├─► model_type_==0: parser_fasterrcnn::Parse()  # FasterRCNN解析 :532-533
    └─► model_type_==1: YoloPoseParse()             # YOLO-Pose解析 :535
            │ yolo_pose_parser.cpp:130-158
            │
            ├─► FieldParse() x3 (stride=8,16,32)    # 多尺度特征解析 :152-154
            │   │ yolo_pose_parser.cpp:19-128
            │   ├─► Sigmoid阈值过滤 :65-68
            │   ├─► DFL解码bbox :74-86
            │   └─► 关键点解码 :101-114
            │
            └─► nms()                               # NMS去重 :155
                │ yolo_pose_parser.cpp:160-220
    │
    ▼ [跟踪]
    ├─► DoMot()                         # 多目标跟踪 :641
    │   │ mono2d_body_det_node.cpp:1096-1137
    │   └─► HobotMot::DoProcess()       # :1123-1128
    │
    ▼ [构建消息]
    ├─► 填充 targets[], disappeared_targets[]  # :644-711
    ├─► 填充 perfs[] (性能统计)                # :716-763
    │
    ▼ [发布]
    └─► msg_publisher_->publish()       # :824
```

---

## (E) 推理与性能

### 预处理详解

| 阶段 | 输入 | 处理 | 输出 | 定位 |
|------|------|------|------|------|
| **图像接收** | NV12 (SharedMem) 或 RGB8/BGR8/NV12 (ROS) | - | 原始图像数据 | :840-857, :967-986 |
| **颜色空间转换** | RGB8/BGR8 | cv_bridge::cvtColorForDisplay → BGR8 | BGR Mat | :871-872 |
| **Resize** | 任意尺寸NV12 | hobot_cv::hobotcv_resize() | 模型输入尺寸NV12 | :893-894, :1013-1014 |
| **金字塔构建** | NV12/BGR | ImageProc::GetNV12PyramidFromNV12Img() 或 GetNV12PyramidFromBGRImg() | NV12PyramidInput | :888-911, :1018-1031 |

**模型输入规格**:
- FasterRCNN: 960x544 NV12
- YOLO-Pose: 640x640 NV12

**定位**: `yolo_pose_parser.h:44-45` (YOLO), 模型文件名暗示尺寸

### 后处理详解

#### FasterRCNN (model_type_=0)

- 使用 `hobot::dnn_node::parser_fasterrcnn::Parse()`
- 输出索引:
  - body_box: index=1
  - head_box: index=3
  - face_box: index=5
  - hand_box: index=7
  - kps: index=8

**定位**: `mono2d_body_det_node.h:117-125`

#### YOLO-Pose (model_type_=1)

| 参数 | 值 | 定位 |
|------|-----|------|
| 输入尺寸 | 640x640 | `yolo_pose_parser.h:44-45` |
| 分数阈值 | 0.5 | `yolo_pose_parser.h:43` |
| NMS IoU阈值 | 0.45 | `yolo_pose_parser.cpp:155` |
| NMS Top-K | 50 | `yolo_pose_parser.cpp:155` |
| NMS最大输入 | 400 | `yolo_pose_parser.h:39` |
| 关键点数量 | 17 (COCO格式) | `yolo_pose_parser.h:47` |
| DFL寄存器数 | 16 | `yolo_pose_parser.h:40` |
| 特征图stride | 8, 16, 32 | `yolo_pose_parser.cpp:150` |

**解码流程** (`yolo_pose_parser.cpp:19-128`):
1. 反Sigmoid阈值过滤 (:29, :65-68)
2. DFL解码bbox (ltrb→xyxy) (:74-98)
3. 关键点解码 (x,y,score) (:101-114)

### 性能统计点

| 统计项 | 类型 | 定位 |
|--------|------|------|
| `{model}_preprocess` | 预处理耗时 | :716-724 |
| `{model}_predict_infer` | BPU推理耗时 | :727-735 |
| `{model}_predict_parse` | 输出解析耗时 | :737-743 |
| `{model}_postprocess` | 后处理耗时 | :747-754 |
| `{model}_pipeline` | 端到端延迟 | :757-763 |
| `input_fps` / `output_fps` | 帧率统计 | :811-818 |

**日志输出**: 每5秒输出一次 (`RCLCPP_WARN_THROTTLE`, :811-818)

### 潜在性能瓶颈

| 瓶颈点 | 原因 | 定位 |
|--------|------|------|
| **BGR→NV12转换** | CPU密集型颜色空间转换 | :871-889 |
| **Resize** | 非模型输入尺寸时需resize | :893-894, :1013-1014 |
| **NMS** | O(n²)复杂度，最大400框 | `yolo_pose_parser.cpp:160-220` |
| **MOT跟踪** | 卡尔曼滤波+匹配 | :641, :1096-1137 |
| **输出排序** | 缓存+排序开销 | :489, `NodeOutputManage` |
| **内存拷贝** | Render时NV12→BGR | :109-121 |

---

## (F) 配置与资源

### 配置文件清单

| 文件 | 用途 | 关键参数 | 加载位置 |
|------|------|----------|----------|
| `iou2_method_param.json` | body/face/head MOT配置 | `match_type: "IOU"`, `iou_thres: 0.2`, `min_score: 0.8` | :454-456 |
| `iou2_euclid_method_param.json` | hand MOT配置 | `match_type: "Euclidean"`, `euclidean_thres: 200` | :454-456 |

**MOT配置映射** (`mono2d_body_det_node.h:137-141`):
```cpp
hobot_mot_configs_ = {
    {"body", "config/iou2_method_param.json"},
    {"face", "config/iou2_method_param.json"},
    {"head", "config/iou2_method_param.json"},
    {"hand", "config/iou2_euclid_method_param.json"}
};
```

### 模型文件

| 平台 | 模型文件 | 模型类型 | 输入尺寸 |
|------|----------|----------|----------|
| X3 | `x3/multitask_body_head_face_hand_kps_960x544.hbm` | FasterRCNN | 960x544 |
| X5 | `x5/multitask_body_head_face_hand_kps_960x544.hbm` | FasterRCNN | 960x544 |
| Rdkultra | `Rdkultra/multitask_body_head_face_hand_kps_960x544.hbm` | FasterRCNN | 960x544 |
| S100 | `s100/yolo11x_pose_nashe_640x640_nv12.hbm` | YOLO-Pose | 640x640 |
| S600 | `s600/yolo11n_pose_nashp_640x640_nv12.hbm` | YOLO-Pose | 640x640 |

### 运行时加载路径

模型文件通过参数 `model_file_name` 指定，默认值:
```cpp
std::string model_file_name_ = "config/multitask_body_head_face_hand_kps_960x544.hbm";
```
**定位**: `mono2d_body_det_node.h:105-106`

实际加载在 `DnnNode::Init()` 中通过 `dnn_node_para_ptr_->model_file` 传递:
**定位**: `mono2d_body_det_node.cpp:467`

---

## (G) 常见运行方式

### 环境变量

| 变量 | 用途 | 值 |
|------|------|-----|
| `CAM_TYPE` | 相机类型选择 | `mipi` / `usb` / `fb` |
| `RMW_FASTRTPS_USE_QOS_FROM_XML` | 零拷贝通信 | `1` (启用) |

**定位**: `mono2d_body_detection.launch.py:38`, `mono2d_body_det_node.cpp:414-428`

### Launch参数

| 参数 | 类型 | 默认值 | 说明 |
|------|------|--------|------|
| `kps_model_file_name` | string | `config/multitask_...hbm` | 模型文件路径 |
| `kps_model_type` | int | 0 | 0=FasterRCNN, 1=YOLO-Pose |
| `kps_track_mode` | int | 1 | 0=不跟踪, 1=跟踪 |
| `mono2d_body_pub_topic` | string | `/hobot_mono2d_body_detection` | AI消息发布topic |
| `smart_topic` | string | `/hobot_mono2d_body_detection` | WebSocket订阅topic |

**定位**: `mono2d_body_detection.launch.py:29-37, 68-71, 132-135`

### 运行模式对比

#### 模式1: MIPI相机 (在线)
```bash
export CAM_TYPE=mipi
ros2 launch mono2d_body_detection mono2d_body_detection.launch.py
```
**数据流**: `mipi_cam → /hbmem_img → mono2d_body_detection → /hobot_mono2d_body_detection`

#### 模式2: USB相机 (在线)
```bash
export CAM_TYPE=usb
ros2 launch mono2d_body_detection mono2d_body_detection.launch.py
```
**数据流**: `hobot_usb_cam → /image → hobot_codec(decode) → /hbmem_img → mono2d_body_detection`

#### 模式3: 本地回放 (离线)
```bash
export CAM_TYPE=fb
ros2 launch mono2d_body_detection mono2d_body_detection.launch.py \
    publish_image_source:=config/person_body.jpg \
    publish_image_format:=jpg \
    publish_output_image_w:=960 \
    publish_output_image_h:=544
```
**数据流**: `hobot_image_publisher → /image → hobot_codec(decode) → /hbmem_img → mono2d_body_detection`

#### 模式4: 无相机启动 (外部图像源)
```bash
ros2 launch mono2d_body_detection mono2d_body_detection_without_camera.launch.py
```
**说明**: 仅启动检测节点，需外部提供 `/hbmem_img` 图像

---

## (H) 二次开发方案（人眼定位）

### 方案1: 新建独立算法节点（低侵入）

#### 架构图
```
mono2d_body_detection → /hobot_mono2d_body_detection → eye_localization_node
                                                              ↓
                                                    /eye_localization_result
```

#### 改动文件

| 文件 | 改动 | 说明 |
|------|------|------|
| 新建 `eye_localization/` | 新包 | 独立ROS2包 |
| `eye_localization_node.cpp` | 新建 | 订阅AI消息，提取face ROI，运行人眼定位模型 |
| `eye_localization_node.h` | 新建 | 节点类定义 |
| `CMakeLists.txt` | 新建 | 编译配置 |
| `package.xml` | 新建 | 依赖声明 |

#### 新增Topic/Msg

| Topic | 消息类型 | 方向 | 说明 |
|-------|----------|------|------|
| `/hobot_mono2d_body_detection` | `ai_msgs/msg/PerceptionTargets` | 订阅 | 获取face bbox |
| `/hbmem_img` 或 `/image_raw` | 图像消息 | 订阅 | 获取原图用于裁剪 |
| `/eye_localization_result` | 自定义或扩展`ai_msgs` | 发布 | 人眼坐标 |

#### 参数设计

```yaml
eye_localization_node:
  ros__parameters:
    model_file_name: "config/eye_localization.hbm"
    input_ai_topic: "/hobot_mono2d_body_detection"
    input_img_topic: "/hbmem_img"
    output_topic: "/eye_localization_result"
    face_roi_expand_ratio: 1.2      # face框扩展比例
    eye_score_threshold: 0.5
    is_shared_mem_sub: 1
```

#### 优缺点

| 优点 | 缺点 |
|------|------|
| 零侵入原仓库，易维护 | 额外通信延迟(~1-2ms) |
| 可独立部署/调试 | 需同步两个节点的图像时间戳 |
| 模块化，可复用 | 需额外订阅原图 |
| 故障隔离 | 两次图像解码开销(如需) |

#### 风险
- **时间戳同步**: AI消息与原图需匹配，可用header.stamp对齐
- **ROI有效性**: face检测可能漏检，需处理空ROI情况

---

### 方案2: 在本节点内加人眼定位分支（低延迟）

#### 架构图
```
图像输入 → 预处理 → body检测推理 → 后处理 → [face ROI] → 人眼定位推理 → 合并结果 → 发布
```

#### 改动文件

| 文件 | 改动位置 | 改动内容 |
|------|----------|----------|
| `include/mono2d_body_det_node.h` | 类成员 (~:145后) | 新增eye模型相关成员变量 |
| `src/mono2d_body_det_node.cpp` | 构造函数 (~:310后) | 加载eye模型、声明参数 |
| `src/mono2d_body_det_node.cpp` | `PostProcess()` (~:609后) | 提取face ROI，调用eye推理 |
| `include/post_process/eye_parser.h` | 新建 | eye模型后处理头文件 |
| `src/post_process/eye_parser.cpp` | 新建 | eye模型后处理实现 |
| `CMakeLists.txt` | 源文件列表 (~:114) | 添加eye_parser.cpp |
| `config/` | 新增 | eye模型文件(.hbm) |

#### 具体改动示例

**1. mono2d_body_det_node.h 新增成员** (约:145后):
```cpp
// Eye localization
bool enable_eye_localization_ = false;
std::string eye_model_file_name_ = "config/eye_localization.hbm";
std::shared_ptr<Model> eye_model_ = nullptr;
float eye_score_threshold_ = 0.5;
float face_roi_expand_ratio_ = 1.2;
```

**2. mono2d_body_det_node.cpp 构造函数新增** (约:310后):
```cpp
this->declare_parameter<int>("enable_eye_localization", 0);
this->declare_parameter<std::string>("eye_model_file_name", eye_model_file_name_);
this->declare_parameter<double>("eye_score_threshold", eye_score_threshold_);
this->get_parameter<int>("enable_eye_localization", enable_eye_localization_);
// ... 加载eye模型
```

**3. PostProcess() 新增eye推理** (约:609后，在face ROI处理后):
```cpp
if (enable_eye_localization_ && roi_type == "face") {
    // 1. 从pyramid裁剪face区域
    // 2. resize到eye模型输入尺寸
    // 3. 调用eye模型推理
    // 4. 解析eye坐标，添加到target.points
}
```

#### 新增Topic/Msg

| Topic | 消息类型 | 说明 |
|-------|----------|------|
| 无新增Topic | - | 复用现有`/hobot_mono2d_body_detection` |
| 扩展points[] | `ai_msgs/msg/Point` | 新增 `type: "eye_kps"` |

#### 参数设计

```yaml
mono2d_body_detection:
  ros__parameters:
    # 原有参数...
    enable_eye_localization: 1          # 启用人眼定位
    eye_model_file_name: "config/eye_localization.hbm"
    eye_score_threshold: 0.5
    face_roi_expand_ratio: 1.2
```

#### 优缺点

| 优点 | 缺点 |
|------|------|
| 最低延迟，无通信开销 | 侵入原代码，维护成本高 |
| 共享pyramid数据，无重复解码 | 增加PostProcess复杂度 |
| 单节点部署简单 | 升级原仓库时需合并冲突 |
| 可复用MOT跟踪结果 | eye模型故障影响整体 |

#### 风险
- **代码耦合**: 修改核心PostProcess，需充分测试
- **性能影响**: eye推理串行执行，增加端到端延迟
- **维护负担**: 原仓库更新时需手动合并

---

### 方案对比总结

| 维度 | 方案1 (独立节点) | 方案2 (内嵌分支) |
|------|------------------|------------------|
| **侵入性** | 零侵入 | 高侵入 |
| **延迟** | +1~2ms | 最优 |
| **维护成本** | 低 | 高 |
| **部署复杂度** | 需启动多节点 | 单节点 |
| **故障隔离** | 好 | 差 |
| **推荐场景** | 原型验证、多团队协作 | 产品化、极致性能 |

### 推荐

- **初期开发/验证阶段**: 采用**方案1**，快速迭代，不影响原有功能
- **产品化/性能敏感场景**: 采用**方案2**，获得最佳延迟表现

---

## 附录: 关键代码定位速查表

| 功能 | 文件 | 行号/函数 |
|------|------|-----------|
| 节点入口 | `src/main.cpp` | :21-29 |
| 构造函数 | `src/mono2d_body_det_node.cpp` | :296-458 |
| 参数声明 | `src/mono2d_body_det_node.cpp` | :298-324 |
| SharedMem订阅 | `src/mono2d_body_det_node.cpp` | :433-439 |
| ROS订阅 | `src/mono2d_body_det_node.cpp` | :447-451 |
| 预处理(SharedMem) | `src/mono2d_body_det_node.cpp` | :966-1094 |
| 预处理(ROS) | `src/mono2d_body_det_node.cpp` | :839-963 |
| 推理调用 | `src/mono2d_body_det_node.cpp` | :829-837 |
| 后处理入口 | `src/mono2d_body_det_node.cpp` | :474-827 |
| FasterRCNN解析 | `src/mono2d_body_det_node.cpp` | :532-533 |
| YOLO-Pose解析 | `src/post_process/yolo_pose_parser.cpp` | :130-158 |
| NMS实现 | `src/post_process/yolo_pose_parser.cpp` | :160-220 |
| MOT跟踪 | `src/mono2d_body_det_node.cpp` | :1096-1137 |
| 消息发布 | `src/mono2d_body_det_node.cpp` | :824 |
| 性能统计 | `src/mono2d_body_det_node.cpp` | :716-763 |

---

*文档生成时间: 2026-01-27*

